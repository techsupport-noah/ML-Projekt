{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe-F-FilmDialoge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeines\n",
    "\n",
    "Eine allgemeine Beschreibung der Laboraufgaben inklusive des Vorgehens, den Bewertungsrichtlinien und der Abgabe finden Sie  <a href=\"ML-allgemein.ipynb\">hier</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenquelle\n",
    "\n",
    "\n",
    "* Laden Sie ihre Daten von http://141.72.190.207/ml_lab/F_dialoge herunter\n",
    "    * Die Daten sind geschützt. \n",
    "        * Sie müssen evtl. in einem Netzwerk der DHBW (z.B. WLAN, VPN, ...) angemeldet sein. \n",
    "        * Sie können sich auf der Webseite mit dem Benutzernamen dhbw und dem Zugangsnamen \"ml_LaB_4$\" anmelden. \n",
    "* Die Daten sind in einem anwendungsspezifischen Format gespeichert.\n",
    "    * Sie finden evtl. Informationen über die Daten in einer \"README\" Datei. \n",
    "    * Finden Sie keine solche Datei sind die Daten selbst erklärend. \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten-Sammlung \n",
    "* besteht aus Dialogen aus verschiedensten Filmen\n",
    "* ist in der Readme Datei beschrieben\n",
    "\n",
    "Erstellen Sie aus den einen Chatbot, der auf eine Frage mit einer Antwort im \"Filmjargon\" antwortet! \n",
    "* Verwenden Sie tiefe Neuronale Netze zu Erstellen des Chatbots! \n",
    "* Passen Sie den Chatbot so an, dass er für unterschiedliche Film-Genres unterschiedlich antwortet! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösung\n",
    "\n",
    "Die Lösung der Aufgabe besteht aus mehreren Teilschritten, welche im Folgenden kurz genannt werden:\n",
    "\n",
    "* Daten einlesen\n",
    "* Daten vorverarbeiten\n",
    "* Model erstellen\n",
    "* Model trainieren\n",
    "* Model abspeichern\n",
    "* Model ausführen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abhängigkeiten des Projekts\n",
    "\n",
    "* Tensorflow 2.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random \n",
    "import re #re = regular expressions\n",
    "import os\n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigene Abhängigkeiten des Projekts\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data_helper as dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konstanten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 30000\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten einlesen\n",
    "\n",
    "Hier werden zuerst die rohen Daten eingelesen und innerhalb der Hilfsfunktion \"readDataToLines\" mit des \"newline\" Zeichen getrennt. Die Daten werden zwei Listen gespeichert, welche dann zurückgegeben werden.\n",
    "Verwendet wurden folgende Funktionen:\n",
    "\n",
    "* \"open\" um die Datei zu öffnen\n",
    "* \"read\" um die Datei zu lesen\n",
    "* \"split\" um die Daten anhand des \"newline\" Zeichen zu trennen und in einer Liste zu speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the files\n",
    "movie_lines, movie_conversations = dh.readDataToLines(\"data/unzipped/movie_lines.txt\", \"data/unzipped/movie_conversations.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten vorverarbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge Fragen: 221616\n",
      "Länge Antworten: 221616\n"
     ]
    }
   ],
   "source": [
    "# extract and mix conversations to a list\n",
    "conversations_list = dh.readConversationsToList(movie_conversations)\n",
    "# random.shuffle(conversations_list) #todo maybe add this later \n",
    "\n",
    "# create a dictionary that maps each line id to the corresponding line\n",
    "id2line = dh.readLinesToDict(movie_lines)\n",
    "\n",
    "# remove all unnecessary characters from the lines and replace short forms with the full words\n",
    "id2line = dh.cleanLines(id2line)\n",
    "\n",
    "# split the conversations into requests and responses, each answer is used as a request for the next answer\n",
    "requests, responses = dh.splitConversationsToRequestAndResponse(conversations_list, id2line)\n",
    "\n",
    "print(f\"Länge Fragen: {len(requests)}\")\n",
    "print(f\"Länge Antworten: {len(responses)}\")\n",
    "\n",
    "# delete temporary variables\n",
    "del(movie_lines, movie_conversations, conversations_list, id2line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter wählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "# get the length of each line of the requests and save the occurrences in a dictionary\n",
    "lengths_request = {}\n",
    "for sentence in requests:\n",
    "    length = len(sentence)\n",
    "    if length in lengths_request:\n",
    "        lengths_request[length] += 1\n",
    "    else:\n",
    "        lengths_request[length] = 1\n",
    "\n",
    "# get the length of each line of the responses and save the occurrences in a dictionary\n",
    "lengths_response = {}\n",
    "for sentence in responses:\n",
    "    length = len(sentence)\n",
    "    if length in lengths_response:\n",
    "        lengths_response[length] += 1\n",
    "    else:\n",
    "        lengths_response[length] = 1\n",
    "\n",
    "# plot the occurrences of the lengths of the requests and responses in the same plot while only showind x values up to 200\n",
    "plt.bar(lengths_request.keys(), lengths_request.values(), label=\"request\")\n",
    "plt.bar(lengths_response.keys(), lengths_response.values(), label=\"response\")\n",
    "plt.xlim(0, 400)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge Fragen: 196695\n",
      "Länge Antworten: 196695\n"
     ]
    }
   ],
   "source": [
    "# based on the result set the parameters\n",
    "max_wordcount_in_sentence = 30\n",
    "\n",
    "# delete requests/responses with length > max_wordcount_in_sentence\n",
    "requests, responses = dh.removeLongSequences(requests, responses, 1, max_wordcount_in_sentence)\n",
    "\n",
    "print(f\"Länge Fragen: {len(requests)}\")\n",
    "print(f\"Länge Antworten: {len(responses)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the size of the dataset\n",
    "requests = requests[:num_examples]\n",
    "responses = responses[:num_examples]\n",
    "\n",
    "# encapsule the requests and responses with the tokens <S> (Start) and <E> (End)\n",
    "# requests = dh.encapsuleWithTokens(requests, '<S>', '<E>')\n",
    "responses = dh.encapsuleWithTokens(responses, '<S>', '<E>')#todo muss das so?\n",
    "\n",
    "\n",
    "# get a dictionary of all unique words with their frequency\n",
    "word2count = dh.getWord2Count(requests, responses)\n",
    "\n",
    "# filter out words with a frequency of 5 or less\n",
    "min_wordFrequency = 20\n",
    "word2count = {k:v for k,v in word2count.items() if v > min_wordFrequency}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man in der obigen Grafik erkennt, sind ab einer Sequenzlänge von 200 nur noch wenige Daten vorhanden. Da die Sequenzlänge maßgeblich auch für den Speicherbedarf in weiteren Schritten ist, wird diese hier auf 200 begrenzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_token = '<UNK>'\n",
    "maxlen = len(word2count) + 1\n",
    "del(word2count)\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=maxlen, oov_token=oov_token, filters='', lower=False)\n",
    "tokenizer.fit_on_texts(requests)\n",
    "tokenizer.fit_on_texts(responses)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tokenizer.texts_to_sequences(requests)\n",
    "target_tensor = tokenizer.texts_to_sequences(responses)\n",
    "\n",
    "max_sen_length = dh.get_maximum_sentence_length(input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "input_tensor = pad_sequences(input_tensor, padding=pad_type, truncating=trunc_type, maxlen=max_sen_length)\n",
    "target_tensor = pad_sequences(target_tensor, padding=pad_type, truncating=trunc_type, maxlen=max_sen_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 715    5   21    1  431    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   7  122    6    1    5   21   63    7    1   14   10    1    1    1\n",
      "    14    1   31  680    5   35   18  506  378   65  149    0    0    0\n",
      "     0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [  15   50    5   87    1  137    5   42  635   20   78  830    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [ 113   43   13    1    1   94   89   43   13 1441    8    1   94   15\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   1  177   38   28  443    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [  58    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   5  159   28  287  655    6   12   13    4  265    8 1330    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [ 227    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [  30    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n",
      "[[   5   21  265    8  605    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   6   11   28  281   14   10    1   23  172  133   10  173   40  345\n",
      "    23    1  126   15    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   4   13    1  215    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   9    6  117    1   83    4   16   60    1 1094   14 1368    8   90\n",
      "     9   56    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   1    6    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [  58    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   4   13  144  675   63   17  307    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [  31    1   25  268    4    8   28    1    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   1  894    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   5   22   29    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n",
      "[[   2    4   13    1   55   85   62   13    4  234   90    8   17    3\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2  476   39   65   95   45   10  506  400  206    3    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   68  284    8  242    9    3    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   75    6   45   90    8  141   15  113   20    1   32  381    3\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2  100  100    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2  305   55   23   42   32    1   50   23    1   11   53    7  281\n",
      "    14    4   77   31    1  443    6  109    1    3    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   48   13  285 1452   27    1    3    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   53    3    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2  324   56  406   99    9   25  106    7  339    1  392  756    1\n",
      "     3    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   58    3    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n",
      "[[   2    5   16   60  536   27    4    9    6   18  341    3    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2    9    6  143   14    7  539  158    9    4   22   39    7  539\n",
      "    19    9    3    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   59   68    6  261    1    3    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   99   95   23  615 1368  597    1   23  107   88  242    1    3\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   15   47    6   28  383    4   16   60  108  174   36  235    8\n",
      "    52   14   59    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   58    3    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2    4   36  244   17  305   10  517  142   10 1132  132   41   26\n",
      "    76   70    5  167    5   21  144   10  110  675    3    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2  153    4    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   64  296  296  591    3    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2   72  121    9   81   27    7  735  657  213    3    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "input_encoder_train, input_encoder_val, input_decoder_train, input_decoder_val = train_test_split(input_tensor, target_tensor, test_size=test_size)\n",
    "\n",
    "print(input_encoder_train[:10])\n",
    "print(input_encoder_val[:10])\n",
    "print(input_decoder_train[:10])\n",
    "print(input_decoder_val[:10])\n",
    "\n",
    "\n",
    "# Decoder Output erstellen\n",
    "output_decoder_train = [i[1:] for i in input_decoder_train]\n",
    "output_decoder_val = [i[1:] for i in input_decoder_val]\n",
    "\n",
    "#Dimension erhöhen\n",
    "output_decoder_train = pad_sequences(output_decoder_train, padding=pad_type, truncating=trunc_type, maxlen=max_sen_length)\n",
    "output_decoder_val = pad_sequences(output_decoder_val, padding=pad_type, truncating=trunc_type, maxlen=max_sen_length)\n",
    "\n",
    "# convert the decoder input to a one-hot encoded vector which the model can use\n",
    "output_decoder_train = tf.keras.utils.to_categorical(output_decoder_train, num_classes=vocab_size, dtype=\"float32\") # using float32 even though it's memory intensive because later steps need it to be float32\n",
    "output_decoder_val = tf.keras.utils.to_categorical(output_decoder_val, num_classes=vocab_size, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model erstellen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDimension = 50 \n",
    "lstm_units = 256\n",
    "max_sentence_length = max_sen_length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "- Input\n",
    "- Embedding\n",
    "- LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tensor for the encoder, shape of each vector is determined by max_length which was also used to pad the data\n",
    "inputEncoderTensor = tf.keras.Input(shape=(None, ), name = \"inputEncoderTensor\")\n",
    "\n",
    "# embedding layer of the encoder, the input is the input tensor, the output is the embedding tensor\n",
    "encoderEmbedding = tf.keras.layers.Embedding(vocab_size, outputDimension, mask_zero=True)(inputEncoderTensor)\n",
    "\n",
    "# LSTM layer of the encoder, the input is the embedding tensor, the output is the output tensor and the hidden state of the encoder\n",
    "encoderLSTM, encoderHiddenState, encoderCellState = tf.keras.layers.LSTM(outputDimension, return_sequences = True, return_state = True)(encoderEmbedding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- Input\n",
    "- Embedding\n",
    "- LSTM\n",
    "- Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tensor for the decoder, shape of each vector is determined by max_length which was also used to pad the data\n",
    "inputDecoderTensor = tf.keras.Input(shape=(None, ))\n",
    "\n",
    "# embedding layer of the decoder, the input is the input tensor, the output is the embedding tensor\n",
    "decoderEmbedding = tf.keras.layers.Embedding(vocab_size, outputDimension, mask_zero=True, trainable = True)(inputDecoderTensor)\n",
    "\n",
    "# LSTM layer of the decoder, the input is the embedding tensor and the state of the previous lstm layer, the output is the output tensor and the hidden state of the decoder\n",
    "decoderLSTM, decoderHiddenState, decoderCellState = tf.keras.layers.LSTM(outputDimension, return_sequences = True, return_state = True)(decoderEmbedding, initial_state = [encoderHiddenState, encoderCellState])\n",
    "\n",
    "# dense layer of the decoder, the input is the output tensor of the lstm layer, the output is the output tensor of the dense layer\n",
    "# the dense layer has the same number of units as the number of words in the dictionary because the output of the dense layer is a vector with a probability for each word in the dictionary\n",
    "decoderDense = tf.keras.layers.Dense(vocab_size, activation = \"softmax\")(decoderLSTM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputEncoderTensor (InputLayer  [(None, None)]      0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 50)     846550      ['inputEncoderTensor[0][0]']     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 50)     846550      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, None, 50),   20200       ['embedding[0][0]']              \n",
      "                                 (None, 50),                                                      \n",
      "                                 (None, 50)]                                                      \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 50),   20200       ['embedding_1[0][0]',            \n",
      "                                 (None, 50),                      'lstm[0][1]',                   \n",
      "                                 (None, 50)]                      'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 16931)  863481      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,596,981\n",
      "Trainable params: 2,596,981\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model \n",
    "model = tf.keras.models.Model([inputEncoderTensor, inputDecoderTensor], decoderDense)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainieren des Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      "480/480 [==============================] - 98s 192ms/step - loss: 1.8315\n",
      "Epoch 2/240\n",
      "480/480 [==============================] - 104s 217ms/step - loss: 1.5830\n",
      "Epoch 3/240\n",
      "480/480 [==============================] - 102s 212ms/step - loss: 1.4869\n",
      "Epoch 4/240\n",
      "480/480 [==============================] - 101s 209ms/step - loss: 1.4406\n",
      "Epoch 5/240\n",
      "480/480 [==============================] - 90s 187ms/step - loss: 1.4052\n",
      "Epoch 6/240\n",
      "480/480 [==============================] - 97s 202ms/step - loss: 1.3795\n",
      "Epoch 7/240\n",
      "480/480 [==============================] - 113s 235ms/step - loss: 1.3585\n",
      "Epoch 8/240\n",
      "480/480 [==============================] - 110s 229ms/step - loss: 1.3395\n",
      "Epoch 9/240\n",
      "480/480 [==============================] - 98s 204ms/step - loss: 1.3248\n",
      "Epoch 10/240\n",
      "480/480 [==============================] - 106s 221ms/step - loss: 1.3127\n",
      "Epoch 11/240\n",
      "480/480 [==============================] - 111s 232ms/step - loss: 1.3018\n",
      "Epoch 12/240\n",
      "480/480 [==============================] - 101s 211ms/step - loss: 1.2916\n",
      "Epoch 13/240\n",
      "480/480 [==============================] - 97s 201ms/step - loss: 1.2824\n",
      "Epoch 14/240\n",
      "480/480 [==============================] - 114s 238ms/step - loss: 1.2740\n",
      "Epoch 15/240\n",
      "480/480 [==============================] - 118s 245ms/step - loss: 1.2665\n",
      "Epoch 16/240\n",
      "480/480 [==============================] - 95s 199ms/step - loss: 1.2594\n",
      "Epoch 17/240\n",
      "480/480 [==============================] - 98s 205ms/step - loss: 1.2531\n",
      "Epoch 18/240\n",
      "480/480 [==============================] - 121s 252ms/step - loss: 1.2471\n",
      "Epoch 19/240\n",
      "480/480 [==============================] - 100s 208ms/step - loss: 1.2417\n",
      "Epoch 20/240\n",
      "480/480 [==============================] - 99s 206ms/step - loss: 1.2365\n",
      "Epoch 21/240\n",
      "480/480 [==============================] - 128s 268ms/step - loss: 1.2316\n",
      "Epoch 22/240\n",
      "480/480 [==============================] - 95s 197ms/step - loss: 1.2268\n",
      "Epoch 23/240\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 1.2222\n",
      "Epoch 24/240\n",
      "480/480 [==============================] - 105s 219ms/step - loss: 1.2178\n",
      "Epoch 25/240\n",
      "480/480 [==============================] - 115s 239ms/step - loss: 1.2135\n",
      "Epoch 26/240\n",
      "480/480 [==============================] - 112s 233ms/step - loss: 1.2094\n",
      "Epoch 27/240\n",
      "480/480 [==============================] - 98s 203ms/step - loss: 1.2054\n",
      "Epoch 28/240\n",
      "480/480 [==============================] - 125s 260ms/step - loss: 1.2014\n",
      "Epoch 29/240\n",
      "480/480 [==============================] - 131s 273ms/step - loss: 1.1976\n",
      "Epoch 30/240\n",
      "480/480 [==============================] - 100s 209ms/step - loss: 1.1940\n",
      "Epoch 31/240\n",
      "480/480 [==============================] - 112s 233ms/step - loss: 1.1904\n",
      "Epoch 32/240\n",
      "480/480 [==============================] - 140s 291ms/step - loss: 1.1870\n",
      "Epoch 33/240\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 1.1836\n",
      "Epoch 34/240\n",
      "480/480 [==============================] - 95s 198ms/step - loss: 1.1801\n",
      "Epoch 35/240\n",
      "480/480 [==============================] - 127s 264ms/step - loss: 1.1769\n",
      "Epoch 36/240\n",
      "480/480 [==============================] - 106s 221ms/step - loss: 1.1735\n",
      "Epoch 37/240\n",
      "480/480 [==============================] - 103s 215ms/step - loss: 1.1704\n",
      "Epoch 38/240\n",
      "480/480 [==============================] - 97s 201ms/step - loss: 1.1674\n",
      "Epoch 39/240\n",
      "480/480 [==============================] - 91s 189ms/step - loss: 1.1643\n",
      "Epoch 40/240\n",
      "480/480 [==============================] - 94s 197ms/step - loss: 1.1614\n",
      "Epoch 41/240\n",
      "480/480 [==============================] - 106s 221ms/step - loss: 1.1585\n",
      "Epoch 42/240\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 1.1558\n",
      "Epoch 43/240\n",
      "480/480 [==============================] - 99s 207ms/step - loss: 1.1529\n",
      "Epoch 44/240\n",
      "480/480 [==============================] - 93s 194ms/step - loss: 1.1502\n",
      "Epoch 45/240\n",
      "480/480 [==============================] - 96s 199ms/step - loss: 1.1475\n",
      "Epoch 46/240\n",
      "480/480 [==============================] - 98s 205ms/step - loss: 1.1449\n",
      "Epoch 47/240\n",
      "480/480 [==============================] - 97s 202ms/step - loss: 1.1423\n",
      "Epoch 48/240\n",
      "480/480 [==============================] - 113s 236ms/step - loss: 1.1398\n",
      "Epoch 49/240\n",
      "480/480 [==============================] - 95s 197ms/step - loss: 1.1374\n",
      "Epoch 50/240\n",
      "480/480 [==============================] - 110s 229ms/step - loss: 1.1351\n",
      "Epoch 51/240\n",
      "480/480 [==============================] - 102s 213ms/step - loss: 1.1326\n",
      "Epoch 52/240\n",
      "480/480 [==============================] - 96s 200ms/step - loss: 1.1301\n",
      "Epoch 53/240\n",
      "480/480 [==============================] - 110s 228ms/step - loss: 1.1279\n",
      "Epoch 54/240\n",
      "480/480 [==============================] - 105s 218ms/step - loss: 1.1255\n",
      "Epoch 55/240\n",
      "480/480 [==============================] - 101s 211ms/step - loss: 1.1233\n",
      "Epoch 56/240\n",
      "480/480 [==============================] - 96s 199ms/step - loss: 1.1212\n",
      "Epoch 57/240\n",
      "480/480 [==============================] - 109s 227ms/step - loss: 1.1190\n",
      "Epoch 58/240\n",
      "480/480 [==============================] - 96s 199ms/step - loss: 1.1169\n",
      "Epoch 59/240\n",
      "480/480 [==============================] - 106s 221ms/step - loss: 1.1148\n",
      "Epoch 60/240\n",
      "480/480 [==============================] - 99s 207ms/step - loss: 1.1127\n",
      "Epoch 61/240\n",
      "480/480 [==============================] - 124s 258ms/step - loss: 1.1107\n",
      "Epoch 62/240\n",
      "480/480 [==============================] - 127s 265ms/step - loss: 1.1086\n",
      "Epoch 63/240\n",
      "480/480 [==============================] - 95s 199ms/step - loss: 1.1066\n",
      "Epoch 64/240\n",
      "480/480 [==============================] - 101s 211ms/step - loss: 1.1047\n",
      "Epoch 65/240\n",
      "480/480 [==============================] - 93s 195ms/step - loss: 1.1027\n",
      "Epoch 66/240\n",
      "480/480 [==============================] - 109s 227ms/step - loss: 1.1008\n",
      "Epoch 67/240\n",
      "480/480 [==============================] - 96s 200ms/step - loss: 1.0990\n",
      "Epoch 68/240\n",
      "480/480 [==============================] - 103s 211ms/step - loss: 1.0974\n",
      "Epoch 69/240\n",
      "480/480 [==============================] - 99s 207ms/step - loss: 1.0953\n",
      "Epoch 70/240\n",
      "480/480 [==============================] - 98s 204ms/step - loss: 1.0935\n",
      "Epoch 71/240\n",
      "480/480 [==============================] - 100s 208ms/step - loss: 1.0917\n",
      "Epoch 72/240\n",
      "480/480 [==============================] - 111s 231ms/step - loss: 1.0899\n",
      "Epoch 73/240\n",
      "480/480 [==============================] - 95s 199ms/step - loss: 1.0881\n",
      "Epoch 74/240\n",
      "480/480 [==============================] - 98s 205ms/step - loss: 1.0864\n",
      "Epoch 75/240\n",
      "480/480 [==============================] - 122s 255ms/step - loss: 1.0847\n",
      "Epoch 76/240\n",
      "480/480 [==============================] - 99s 207ms/step - loss: 1.0833\n",
      "Epoch 77/240\n",
      "480/480 [==============================] - 99s 206ms/step - loss: 1.0818\n",
      "Epoch 78/240\n",
      "480/480 [==============================] - 97s 201ms/step - loss: 1.0799\n",
      "Epoch 79/240\n",
      "480/480 [==============================] - 115s 239ms/step - loss: 1.0782\n",
      "Epoch 80/240\n",
      "480/480 [==============================] - 130s 271ms/step - loss: 1.0770\n",
      "Epoch 81/240\n",
      "480/480 [==============================] - 111s 232ms/step - loss: 1.0753\n",
      "Epoch 82/240\n",
      "480/480 [==============================] - 99s 206ms/step - loss: 1.0737\n",
      "Epoch 83/240\n",
      "480/480 [==============================] - 94s 196ms/step - loss: 1.0729\n",
      "Epoch 84/240\n",
      "480/480 [==============================] - 106s 221ms/step - loss: 1.0717\n",
      "Epoch 85/240\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 1.0696\n",
      "Epoch 86/240\n",
      "480/480 [==============================] - 96s 201ms/step - loss: 1.0676\n",
      "Epoch 87/240\n",
      "480/480 [==============================] - 104s 218ms/step - loss: 1.0664\n",
      "Epoch 88/240\n",
      "480/480 [==============================] - 99s 206ms/step - loss: 1.0655\n",
      "Epoch 89/240\n",
      "480/480 [==============================] - 102s 213ms/step - loss: 1.0646\n",
      "Epoch 90/240\n",
      "480/480 [==============================] - 96s 200ms/step - loss: 1.0629\n",
      "Epoch 91/240\n",
      "480/480 [==============================] - 116s 241ms/step - loss: 1.0609\n",
      "Epoch 92/240\n",
      "480/480 [==============================] - 104s 216ms/step - loss: 1.0599\n",
      "Epoch 93/240\n",
      "480/480 [==============================] - 102s 213ms/step - loss: 1.0585\n",
      "Epoch 94/240\n",
      "480/480 [==============================] - 97s 203ms/step - loss: 1.0572\n",
      "Epoch 95/240\n",
      "480/480 [==============================] - 101s 212ms/step - loss: 1.0561\n",
      "Epoch 96/240\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 1.0549\n",
      "Epoch 97/240\n",
      "480/480 [==============================] - 97s 203ms/step - loss: 1.0540\n",
      "Epoch 98/240\n",
      "480/480 [==============================] - 99s 207ms/step - loss: 1.0525\n",
      "Epoch 99/240\n",
      "480/480 [==============================] - 98s 205ms/step - loss: 1.0512\n",
      "Epoch 100/240\n",
      "480/480 [==============================] - 95s 198ms/step - loss: 1.0499\n",
      "Epoch 101/240\n",
      "480/480 [==============================] - 100s 208ms/step - loss: 1.0490\n",
      "Epoch 102/240\n",
      "480/480 [==============================] - 99s 205ms/step - loss: 1.0480\n",
      "Epoch 103/240\n",
      "480/480 [==============================] - 100s 209ms/step - loss: 1.0471\n",
      "Epoch 104/240\n",
      "480/480 [==============================] - 107s 222ms/step - loss: 1.0456\n",
      "Epoch 105/240\n",
      "480/480 [==============================] - 106s 220ms/step - loss: 1.0442\n",
      "Epoch 106/240\n",
      "480/480 [==============================] - 106s 221ms/step - loss: 1.0433\n",
      "Epoch 107/240\n",
      "480/480 [==============================] - 115s 240ms/step - loss: 1.0421\n",
      "Epoch 108/240\n",
      "480/480 [==============================] - 106s 221ms/step - loss: 1.0411\n",
      "Epoch 109/240\n",
      "480/480 [==============================] - 116s 241ms/step - loss: 1.0405\n",
      "Epoch 110/240\n",
      "480/480 [==============================] - 99s 206ms/step - loss: 1.0395\n",
      "Epoch 111/240\n",
      "480/480 [==============================] - 97s 202ms/step - loss: 1.0380\n",
      "Epoch 112/240\n",
      "480/480 [==============================] - 117s 244ms/step - loss: 1.0372\n",
      "Epoch 113/240\n",
      "480/480 [==============================] - 115s 240ms/step - loss: 1.0358\n",
      "Epoch 114/240\n",
      "480/480 [==============================] - 103s 215ms/step - loss: 1.0353\n",
      "Epoch 115/240\n",
      "480/480 [==============================] - 104s 216ms/step - loss: 1.0341\n",
      "Epoch 116/240\n",
      "480/480 [==============================] - 104s 216ms/step - loss: 1.0330\n",
      "Epoch 117/240\n",
      "480/480 [==============================] - 105s 218ms/step - loss: 1.0322\n",
      "Epoch 118/240\n",
      "480/480 [==============================] - 109s 227ms/step - loss: 1.0311\n",
      "Epoch 119/240\n",
      "480/480 [==============================] - 105s 218ms/step - loss: 1.0303\n",
      "Epoch 120/240\n",
      "480/480 [==============================] - 108s 224ms/step - loss: 1.0293\n",
      "Epoch 121/240\n",
      "480/480 [==============================] - 98s 204ms/step - loss: 1.0281\n",
      "Epoch 122/240\n",
      "480/480 [==============================] - 107s 222ms/step - loss: 1.0271\n",
      "Epoch 123/240\n",
      "480/480 [==============================] - 98s 204ms/step - loss: 1.0266\n",
      "Epoch 124/240\n",
      "480/480 [==============================] - 98s 204ms/step - loss: 1.0252\n",
      "Epoch 125/240\n",
      "480/480 [==============================] - 117s 243ms/step - loss: 1.0246\n",
      "Epoch 126/240\n",
      "480/480 [==============================] - 100s 208ms/step - loss: 1.0242\n",
      "Epoch 127/240\n",
      "480/480 [==============================] - 99s 206ms/step - loss: 1.0235\n",
      "Epoch 128/240\n",
      "480/480 [==============================] - 102s 212ms/step - loss: 1.0224\n",
      "Epoch 129/240\n",
      "480/480 [==============================] - 100s 208ms/step - loss: 1.0211\n",
      "Epoch 130/240\n",
      "480/480 [==============================] - 100s 208ms/step - loss: 1.0205\n",
      "Epoch 131/240\n",
      "480/480 [==============================] - 109s 227ms/step - loss: 1.0195\n",
      "Epoch 132/240\n",
      "480/480 [==============================] - 97s 202ms/step - loss: 1.0186\n",
      "Epoch 133/240\n",
      "480/480 [==============================] - 97s 202ms/step - loss: 1.0185\n",
      "Epoch 134/240\n",
      "480/480 [==============================] - 97s 203ms/step - loss: 1.0176\n",
      "Epoch 135/240\n",
      "480/480 [==============================] - 100s 209ms/step - loss: 1.0161\n",
      "Epoch 136/240\n",
      "480/480 [==============================] - 122s 254ms/step - loss: 1.0154\n",
      "Epoch 137/240\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 1.0142\n",
      "Epoch 138/240\n",
      "480/480 [==============================] - 96s 200ms/step - loss: 1.0137\n",
      "Epoch 139/240\n",
      "480/480 [==============================] - 96s 201ms/step - loss: 1.0134\n",
      "Epoch 140/240\n",
      "480/480 [==============================] - 102s 212ms/step - loss: 1.0128\n",
      "Epoch 141/240\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 1.0125\n",
      "Epoch 142/240\n",
      "480/480 [==============================] - 100s 207ms/step - loss: 1.0115\n",
      "Epoch 143/240\n",
      "480/480 [==============================] - 99s 207ms/step - loss: 1.0103\n",
      "Epoch 144/240\n",
      "480/480 [==============================] - 98s 205ms/step - loss: 1.0097\n",
      "Epoch 145/240\n",
      "480/480 [==============================] - 109s 227ms/step - loss: 1.0082\n",
      "Epoch 146/240\n",
      "480/480 [==============================] - 111s 230ms/step - loss: 1.0079\n",
      "Epoch 147/240\n",
      "480/480 [==============================] - 102s 212ms/step - loss: 1.0073\n",
      "Epoch 148/240\n",
      "480/480 [==============================] - 103s 215ms/step - loss: 1.0064\n",
      "Epoch 149/240\n",
      "480/480 [==============================] - 98s 205ms/step - loss: 1.0056\n",
      "Epoch 150/240\n",
      "480/480 [==============================] - 105s 218ms/step - loss: 1.0060\n",
      "Epoch 151/240\n",
      "480/480 [==============================] - 103s 215ms/step - loss: 1.0050\n",
      "Epoch 152/240\n",
      "480/480 [==============================] - 107s 223ms/step - loss: 1.0044\n",
      "Epoch 153/240\n",
      "480/480 [==============================] - 100s 208ms/step - loss: 1.0036\n",
      "Epoch 154/240\n",
      "480/480 [==============================] - 129s 269ms/step - loss: 1.0033\n",
      "Epoch 155/240\n",
      "480/480 [==============================] - 116s 242ms/step - loss: 1.0019\n",
      "Epoch 156/240\n",
      "480/480 [==============================] - 99s 206ms/step - loss: 1.0013\n",
      "Epoch 157/240\n",
      "480/480 [==============================] - 100s 208ms/step - loss: 1.0005\n",
      "Epoch 158/240\n",
      "480/480 [==============================] - 102s 212ms/step - loss: 0.9998\n",
      "Epoch 159/240\n",
      "480/480 [==============================] - 99s 206ms/step - loss: 0.9991\n",
      "Epoch 160/240\n",
      "480/480 [==============================] - 100s 207ms/step - loss: 0.9986\n",
      "Epoch 161/240\n",
      "480/480 [==============================] - 99s 207ms/step - loss: 0.9979\n",
      "Epoch 162/240\n",
      "480/480 [==============================] - 104s 217ms/step - loss: 0.9975\n",
      "Epoch 163/240\n",
      "480/480 [==============================] - 116s 242ms/step - loss: 0.9967\n",
      "Epoch 164/240\n",
      "480/480 [==============================] - 101s 211ms/step - loss: 0.9973\n",
      "Epoch 165/240\n",
      "480/480 [==============================] - 99s 206ms/step - loss: 0.9967\n",
      "Epoch 166/240\n",
      "480/480 [==============================] - 117s 244ms/step - loss: 0.9958\n",
      "Epoch 167/240\n",
      "480/480 [==============================] - 105s 219ms/step - loss: 0.9945\n",
      "Epoch 168/240\n",
      "480/480 [==============================] - 101s 211ms/step - loss: 0.9938\n",
      "Epoch 169/240\n",
      "480/480 [==============================] - 113s 236ms/step - loss: 0.9933\n",
      "Epoch 170/240\n",
      "480/480 [==============================] - 105s 218ms/step - loss: 0.9935\n",
      "Epoch 171/240\n",
      "480/480 [==============================] - 102s 213ms/step - loss: 0.9923\n",
      "Epoch 172/240\n",
      "480/480 [==============================] - 98s 205ms/step - loss: 0.9913\n",
      "Epoch 173/240\n",
      "480/480 [==============================] - 114s 237ms/step - loss: 0.9914\n",
      "Epoch 174/240\n",
      "480/480 [==============================] - 100s 208ms/step - loss: 0.9909\n",
      "Epoch 175/240\n",
      "480/480 [==============================] - 102s 213ms/step - loss: 0.9905\n",
      "Epoch 176/240\n",
      "480/480 [==============================] - 98s 204ms/step - loss: 0.9899\n",
      "Epoch 177/240\n",
      "480/480 [==============================] - 99s 206ms/step - loss: 0.9910\n",
      "Epoch 178/240\n",
      "480/480 [==============================] - 118s 246ms/step - loss: 0.9884\n",
      "Epoch 179/240\n",
      "480/480 [==============================] - 118s 246ms/step - loss: 0.9876\n",
      "Epoch 180/240\n",
      "480/480 [==============================] - 99s 207ms/step - loss: 0.9876\n",
      "Epoch 181/240\n",
      "480/480 [==============================] - 105s 219ms/step - loss: 0.9871\n",
      "Epoch 182/240\n",
      "480/480 [==============================] - 103s 215ms/step - loss: 0.9872\n",
      "Epoch 183/240\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 0.9866\n",
      "Epoch 184/240\n",
      "480/480 [==============================] - 113s 236ms/step - loss: 0.9853\n",
      "Epoch 185/240\n",
      "480/480 [==============================] - 101s 211ms/step - loss: 0.9846\n",
      "Epoch 186/240\n",
      "480/480 [==============================] - 117s 244ms/step - loss: 0.9837\n",
      "Epoch 187/240\n",
      "480/480 [==============================] - 118s 245ms/step - loss: 0.9839\n",
      "Epoch 188/240\n",
      "480/480 [==============================] - 100s 209ms/step - loss: 0.9834\n",
      "Epoch 189/240\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 0.9824\n",
      "Epoch 190/240\n",
      "480/480 [==============================] - 102s 213ms/step - loss: 0.9828\n",
      "Epoch 191/240\n",
      "480/480 [==============================] - 105s 218ms/step - loss: 0.9830\n",
      "Epoch 192/240\n",
      "480/480 [==============================] - 119s 248ms/step - loss: 0.9814\n",
      "Epoch 193/240\n",
      "480/480 [==============================] - 102s 213ms/step - loss: 0.9810\n",
      "Epoch 194/240\n",
      "480/480 [==============================] - 112s 233ms/step - loss: 0.9807\n",
      "Epoch 195/240\n",
      "480/480 [==============================] - 103s 214ms/step - loss: 0.9803\n",
      "Epoch 196/240\n",
      "480/480 [==============================] - 107s 223ms/step - loss: 0.9794\n",
      "Epoch 197/240\n",
      "480/480 [==============================] - 102s 212ms/step - loss: 0.9789\n",
      "Epoch 198/240\n",
      "480/480 [==============================] - 124s 259ms/step - loss: 0.9789\n",
      "Epoch 199/240\n",
      "480/480 [==============================] - 106s 221ms/step - loss: 0.9787\n",
      "Epoch 200/240\n",
      "480/480 [==============================] - 113s 235ms/step - loss: 0.9777\n",
      "Epoch 201/240\n",
      "480/480 [==============================] - 102s 212ms/step - loss: 0.9778\n",
      "Epoch 202/240\n",
      "480/480 [==============================] - 117s 243ms/step - loss: 0.9771\n",
      "Epoch 203/240\n",
      "480/480 [==============================] - 101s 210ms/step - loss: 0.9770\n",
      "Epoch 204/240\n",
      "480/480 [==============================] - 103s 215ms/step - loss: 0.9776\n",
      "Epoch 205/240\n",
      "480/480 [==============================] - 108s 225ms/step - loss: 0.9753\n",
      "Epoch 206/240\n",
      "480/480 [==============================] - 101s 211ms/step - loss: 0.9760\n",
      "Epoch 207/240\n",
      "480/480 [==============================] - 113s 235ms/step - loss: 0.9755\n",
      "Epoch 208/240\n",
      "480/480 [==============================] - 94s 195ms/step - loss: 0.9748\n",
      "Epoch 209/240\n",
      "480/480 [==============================] - 129s 268ms/step - loss: 0.9742\n",
      "Epoch 210/240\n",
      "480/480 [==============================] - 126s 262ms/step - loss: 0.9742\n",
      "Epoch 211/240\n",
      "480/480 [==============================] - 107s 222ms/step - loss: 0.9750\n",
      "Epoch 212/240\n",
      "480/480 [==============================] - 108s 225ms/step - loss: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b9b0b0ad70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate an early stopping callback to stop training when the validation loss stops improving so that the model doesn't overfit\n",
    "# waits 3 epochs before stopping\n",
    "# use val_loss as the metric because categorical_crossentropy calculates the difference between the predicted and actual values and by monitoring wether or not the loss would be decreasing or increasing we can see if the model is improving or not\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "# Train the model on the training data and evaluate it on the validation data\n",
    "model.fit([input_encoder_train, input_decoder_train], output_decoder_train, epochs=240, batch_size=50, callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 24s 96ms/step - loss: 1.4551\n",
      "Test loss: 1.4551364183425903\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set and store the results\n",
    "\n",
    "loss = model.evaluate([input_encoder_val, input_decoder_val], output_decoder_val)\n",
    "print('Test loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model abspeichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell speichern\n",
    "dh.save_model(model, 'model.h5')\n",
    "\n",
    "# # Gewichte speichern\n",
    "# for layer in model.layers:\n",
    "#     weights = layer.get_weights()\n",
    "#     if weights != []:\n",
    "#         np.savez(f'models/{layer.name}.npz', weights, dtype=object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two inputs for the state vectors returned by encoder\n",
    "dec_state_input_h = Input(shape=(outputDimension,))\n",
    "dec_state_input_c = Input(shape=(outputDimension,))\n",
    "dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
    "# these state vectors are used as an initial state \n",
    "# for LSTM layer in the inference decoder\n",
    "# third input is the Embedding layer as explained above  \n",
    "decoderLSTM = tf.keras.layers.LSTM(outputDimension, return_sequences = True, return_state = True) \n",
    "dec_outputs, state_h, state_c = decoderLSTM(decoderEmbedding,\n",
    "                                initial_state=dec_states_inputs)\n",
    "dec_states = [state_h, state_c]\n",
    "# Dense layer is used to return OHE predicted word\n",
    "dec_outputs = tf.keras.layers.Dense(vocab_size, activation = \"softmax\")(dec_outputs)\n",
    "dec_model = Model(\n",
    "    inputs=[inputDecoderTensor] + dec_states_inputs,\n",
    "    outputs=[dec_outputs] + dec_states)\n",
    "\n",
    "# single encoder input is a question, represented as a sequence \n",
    "# of integers padded with zeros\n",
    "enc_model = Model(inputs=inputEncoderTensor, outputs=[encoderHiddenState, encoderCellState])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tokens(sentence: str):\n",
    "    # convert input string to lowercase, \n",
    "    # then split it by whitespaces\n",
    "    words = sentence.lower().split()\n",
    "    # and then convert to a sequence \n",
    "    # of integers padded with zeros\n",
    "    tokens_list = list()\n",
    "    for current_word in words:\n",
    "        result = tokenizer.word_index.get(current_word, '')\n",
    "        if result != '':\n",
    "            tokens_list.append(result)\n",
    "    return pad_sequences([tokens_list],\n",
    "                         maxlen=max_sen_length,\n",
    "                         padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      " crotch crotch\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      " crotch crotch crotch\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      " crotch crotch crotch allure allure\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      " crotch crotch crotch allure allure allure\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      " crotch crotch crotch allure allure allure allure\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      " crotch crotch crotch allure allure allure allure allure\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin darlin\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin darlin tracy\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin darlin tracy tracy\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin darlin tracy tracy tracy\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin darlin tracy tracy tracy infirmary\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin darlin tracy tracy tracy infirmary tracy\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin darlin tracy tracy tracy infirmary tracy junkie\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin darlin tracy tracy tracy infirmary tracy junkie junkie\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin darlin tracy tracy tracy infirmary tracy junkie junkie doubted\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      " crotch crotch crotch allure allure allure allure allure pray pray fabric snuffboxes snuffboxes entity restored restored restored toughens toughens toughens vatican darlin darlin darlin tracy tracy tracy infirmary tracy junkie junkie doubted pianist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# encode the input sequence into state vectors\n",
    "states_values = enc_model.predict(\n",
    "    str_to_tokens(\"How are you?\"))\n",
    "# start with a target sequence of size 1 - word 'start'   \n",
    "empty_target_seq = np.zeros((1, 1))\n",
    "empty_target_seq[0, 0] = tokenizer.word_index['<S>']\n",
    "stop_condition = False\n",
    "decoded_translation = ''\n",
    "while not stop_condition:\n",
    "    # feed the state vectors and 1-word target sequence \n",
    "    # to the decoder to produce predictions for the next word\n",
    "    dec_outputs, h, c = dec_model.predict([empty_target_seq] \n",
    "                                            + states_values)                 # sample the next word using these predictions\n",
    "    sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
    "    sampled_word = None\n",
    "    # append the sampled word to the target sequence\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if sampled_word_index == index:\n",
    "            if word != '<E>':\n",
    "                decoded_translation += ' {}'.format(word)\n",
    "            sampled_word = word\n",
    "    # repeat until we generate the end-of-sequence word 'end' \n",
    "    # or we hit the length of answer limit\n",
    "    if sampled_word == '<E>' \\\n",
    "            or len(decoded_translation.split()) \\\n",
    "            > max_sen_length:\n",
    "        stop_condition = True\n",
    "    # prepare next iteration\n",
    "    empty_target_seq = np.zeros((1, 1))\n",
    "    empty_target_seq[0, 0] = sampled_word_index\n",
    "    states_values = [h, c]    \n",
    "    print(decoded_translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9978dee63576bf3eb01fd0099124cb1b0d7ef3663923ee832c1b14872d283213"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
